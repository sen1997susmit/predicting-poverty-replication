{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the images marked as valid per cluster, we pass them through the CNN and extract their feature vectors. the results are stored at a per-country basis. For example, all Malawi feature extractions will go into results/malawi_2016/cnn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '..'\n",
    "COUNTRIES_DIR = os.path.join(BASE_DIR, 'data', 'countries')\n",
    "PROCESSED_DIR = os.path.join(BASE_DIR, 'data', 'processed')\n",
    "RESULTS_DIR = os.path.join(BASE_DIR, 'results')\n",
    "CNN_TRAIN_IMAGE_DIR = os.path.join(BASE_DIR, 'data', 'cnn_images')\n",
    "CNN_DIR = os.path.join(BASE_DIR, 'models', 'trained_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "for country in ['malawi_2016', 'ethiopia_2015', 'nigeria_2015']:\n",
    "    os.makedirs(os.path.join(RESULTS_DIR, country), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extract with CNN\n",
    "If you have run this step before, you can skip it and run the commented out code in the next section to quick-start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_images = pd.read_csv(os.path.join(PROCESSED_DIR, 'image_download_actual.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>image_lat</th>\n",
       "      <th>image_lon</th>\n",
       "      <th>cluster_lat</th>\n",
       "      <th>cluster_lon</th>\n",
       "      <th>cons_pc</th>\n",
       "      <th>nightlights</th>\n",
       "      <th>country</th>\n",
       "      <th>nightlights_bin</th>\n",
       "      <th>is_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-17.09515_35.17229723579403_-17.09515_35.21721...</td>\n",
       "      <td>-17.095150</td>\n",
       "      <td>35.172297</td>\n",
       "      <td>-17.09515</td>\n",
       "      <td>35.217213</td>\n",
       "      <td>1.423239</td>\n",
       "      <td>0.025206</td>\n",
       "      <td>mw</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-17.08017807859801_35.17229723579403_-17.09515...</td>\n",
       "      <td>-17.080178</td>\n",
       "      <td>35.172297</td>\n",
       "      <td>-17.09515</td>\n",
       "      <td>35.217213</td>\n",
       "      <td>1.423239</td>\n",
       "      <td>0.025206</td>\n",
       "      <td>mw</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-17.125093842803985_35.18726915719602_-17.0951...</td>\n",
       "      <td>-17.125094</td>\n",
       "      <td>35.187269</td>\n",
       "      <td>-17.09515</td>\n",
       "      <td>35.217213</td>\n",
       "      <td>1.423239</td>\n",
       "      <td>0.025206</td>\n",
       "      <td>mw</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-17.140065764205975_35.20224107859801_-17.0951...</td>\n",
       "      <td>-17.140066</td>\n",
       "      <td>35.202241</td>\n",
       "      <td>-17.09515</td>\n",
       "      <td>35.217213</td>\n",
       "      <td>1.423239</td>\n",
       "      <td>0.025206</td>\n",
       "      <td>mw</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-17.065206157196016_35.20224107859801_-17.0951...</td>\n",
       "      <td>-17.065206</td>\n",
       "      <td>35.202241</td>\n",
       "      <td>-17.09515</td>\n",
       "      <td>35.217213</td>\n",
       "      <td>1.423239</td>\n",
       "      <td>0.025206</td>\n",
       "      <td>mw</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_name  image_lat  image_lon  \\\n",
       "0  -17.09515_35.17229723579403_-17.09515_35.21721... -17.095150  35.172297   \n",
       "1  -17.08017807859801_35.17229723579403_-17.09515... -17.080178  35.172297   \n",
       "2  -17.125093842803985_35.18726915719602_-17.0951... -17.125094  35.187269   \n",
       "3  -17.140065764205975_35.20224107859801_-17.0951... -17.140066  35.202241   \n",
       "4  -17.065206157196016_35.20224107859801_-17.0951... -17.065206  35.202241   \n",
       "\n",
       "   cluster_lat  cluster_lon   cons_pc  nightlights country  nightlights_bin  \\\n",
       "0    -17.09515    35.217213  1.423239     0.025206      mw                0   \n",
       "1    -17.09515    35.217213  1.423239     0.025206      mw                0   \n",
       "2    -17.09515    35.217213  1.423239     0.025206      mw                0   \n",
       "3    -17.09515    35.217213  1.423239     0.025206      mw                0   \n",
       "4    -17.09515    35.217213  1.423239     0.025206      mw                0   \n",
       "\n",
       "   is_train  \n",
       "0      True  \n",
       "1      True  \n",
       "2     False  \n",
       "3      True  \n",
       "4      True  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_images.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda as backend\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using {device} as backend')\n",
    "model = torch.load(CNN_DIR, map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Dropout(p=0.5, inplace=False)\n",
       "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (4): ReLU(inplace=True)\n",
       "  (5): Dropout(p=0.5, inplace=False)\n",
       "  (6): Linear(in_features=4096, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rip off the final layers\n",
    "model.classifier = model.classifier[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Dropout(p=0.5, inplace=False)\n",
       "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c14651be94a48bc95f289f5310e41a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=495.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "603833349e554916a46a4b00e5840582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=307.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b4e14b2c64548029212b61ab40db408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=132.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "transformer = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "# custom dataset for fast image loading and processing\n",
    "# does not follow the usual style of folder -> folder for each class -> image\n",
    "# we just want one folder with images\n",
    "class ForwardPassDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_dir, transformer):\n",
    "        self.image_dir = image_dir\n",
    "        self.image_list = os.listdir(self.image_dir)\n",
    "        self.transformer = transformer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_name = self.image_list[index]\n",
    "\n",
    "        # Load image\n",
    "        X = self.filename_to_im_tensor(self.image_dir + '/' + image_name)\n",
    "        \n",
    "        # dataloaders need to return a label, but for the forward pass we don't really care\n",
    "        return X, -1\n",
    "    \n",
    "    def filename_to_im_tensor(self, file):\n",
    "        im = plt.imread(file)[:,:,:3]\n",
    "        im = self.transformer(im)\n",
    "        return im\n",
    "\n",
    "model.eval()  \n",
    "classes = [0, 1, 2]\n",
    "# shape of final array will be (num_validation_images, 4096)\n",
    "# we also want to record the image each index represents\n",
    "feats = np.zeros(((~df_images['is_train']).sum(), 4096))\n",
    "image_order = []\n",
    "i = 0\n",
    "for c in classes:\n",
    "    # use the validation images to do the forward pass\n",
    "    dataset = ForwardPassDataset(os.path.join(CNN_TRAIN_IMAGE_DIR, 'valid', str(c)), transformer)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False, num_workers=4)\n",
    "    image_order += dataset.image_list\n",
    "    # forward pass for this class\n",
    "    for inputs, _ in tqdm(dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        feats[i:i+len(inputs),:] = outputs.cpu().detach().numpy()\n",
    "        i += len(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.26415765, -0.28140783, -0.29993755, ...,  0.33739716,\n",
       "        -0.96456331, -0.95310527],\n",
       "       [ 0.55027246, -0.06091447,  0.11403629, ..., -0.08996978,\n",
       "        -0.62236136, -0.96085918],\n",
       "       [ 0.52193987, -0.29220241, -0.45371717, ...,  0.34175205,\n",
       "        -1.1439786 , -0.85960728],\n",
       "       ...,\n",
       "       [-0.50936353,  0.39209121, -0.29870456, ...,  0.0661362 ,\n",
       "         0.43009469, -0.34069228],\n",
       "       [ 0.24428365,  0.07818466, -0.89307284, ...,  0.29522306,\n",
       "        -0.72958505, -1.24356151],\n",
       "       [-0.30123377,  0.6785413 , -0.19940855, ...,  0.14395328,\n",
       "         0.52420121, -1.16047859]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>feat_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.513181862198008_39.768191057994024_10.52815...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-14.632534157196016_34.981995235794024_-14.662...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-14.526346764205977_35.593520078598004_-14.481...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.4290196173360155_7.26950147266_7.45896346014...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-10.405547698244352_34.14279535535209_-10.4038...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_name  feat_index\n",
       "0  10.513181862198008_39.768191057994024_10.52815...           0\n",
       "1  -14.632534157196016_34.981995235794024_-14.662...           1\n",
       "2  -14.526346764205977_35.593520078598004_-14.481...           2\n",
       "3  7.4290196173360155_7.26950147266_7.45896346014...           3\n",
       "4  -10.405547698244352_34.14279535535209_-10.4038...           4"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_pass_df = pd.DataFrame.from_dict({'image_name': image_order, 'feat_index': np.arange(len(image_order))})\n",
    "forward_pass_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_consumption = pd.merge(left=df_images, right=forward_pass_df, on='image_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have we maintained all validation images?\n",
    "assert len(df_consumption) == (~df_images['is_train']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>image_lat</th>\n",
       "      <th>image_lon</th>\n",
       "      <th>cluster_lat</th>\n",
       "      <th>cluster_lon</th>\n",
       "      <th>cons_pc</th>\n",
       "      <th>nightlights</th>\n",
       "      <th>country</th>\n",
       "      <th>nightlights_bin</th>\n",
       "      <th>is_train</th>\n",
       "      <th>feat_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-17.125093842803985_35.18726915719602_-17.0951...</td>\n",
       "      <td>-17.125094</td>\n",
       "      <td>35.187269</td>\n",
       "      <td>-17.095150</td>\n",
       "      <td>35.217213</td>\n",
       "      <td>1.423239</td>\n",
       "      <td>0.025206</td>\n",
       "      <td>mw</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-17.140065764205975_35.232184921401995_-17.095...</td>\n",
       "      <td>-17.140066</td>\n",
       "      <td>35.232185</td>\n",
       "      <td>-17.095150</td>\n",
       "      <td>35.217213</td>\n",
       "      <td>1.423239</td>\n",
       "      <td>0.025206</td>\n",
       "      <td>mw</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-17.065206157196016_35.262128764205976_-17.095...</td>\n",
       "      <td>-17.065206</td>\n",
       "      <td>35.262129</td>\n",
       "      <td>-17.095150</td>\n",
       "      <td>35.217213</td>\n",
       "      <td>1.423239</td>\n",
       "      <td>0.025206</td>\n",
       "      <td>mw</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-17.07737907859801_35.069727235794026_-17.0923...</td>\n",
       "      <td>-17.077379</td>\n",
       "      <td>35.069727</td>\n",
       "      <td>-17.092351</td>\n",
       "      <td>35.114643</td>\n",
       "      <td>1.266204</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>mw</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-17.137266764205975_35.08469915719602_-17.0923...</td>\n",
       "      <td>-17.137267</td>\n",
       "      <td>35.084699</td>\n",
       "      <td>-17.092351</td>\n",
       "      <td>35.114643</td>\n",
       "      <td>1.266204</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>mw</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_name  image_lat  image_lon  \\\n",
       "0  -17.125093842803985_35.18726915719602_-17.0951... -17.125094  35.187269   \n",
       "1  -17.140065764205975_35.232184921401995_-17.095... -17.140066  35.232185   \n",
       "2  -17.065206157196016_35.262128764205976_-17.095... -17.065206  35.262129   \n",
       "3  -17.07737907859801_35.069727235794026_-17.0923... -17.077379  35.069727   \n",
       "4  -17.137266764205975_35.08469915719602_-17.0923... -17.137267  35.084699   \n",
       "\n",
       "   cluster_lat  cluster_lon   cons_pc  nightlights country  nightlights_bin  \\\n",
       "0   -17.095150    35.217213  1.423239     0.025206      mw                0   \n",
       "1   -17.095150    35.217213  1.423239     0.025206      mw                0   \n",
       "2   -17.095150    35.217213  1.423239     0.025206      mw                0   \n",
       "3   -17.092351    35.114643  1.266204     0.000000      mw                0   \n",
       "4   -17.092351    35.114643  1.266204     0.000000      mw                0   \n",
       "\n",
       "   is_train  feat_index  \n",
       "0     False         318  \n",
       "1     False        1861  \n",
       "2     False         836  \n",
       "3     False          18  \n",
       "4     False        1051  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_consumption.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Features\n",
    "For each country, we aggregate the image features per cluster and save them to results/country/cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_abbrv = ['mw', 'eth', 'ng']\n",
    "country_dir = ['malawi_2016', 'ethiopia_2015', 'nigeria_2015']\n",
    "\n",
    "for ca, cd in zip(country_abbrv, country_dir):\n",
    "    df_c = df_consumption[df_consumption['country'] == ca]\n",
    "    group = df_c.groupby(['cluster_lat', 'cluster_lon'])\n",
    "    x = np.zeros((len(group), 4096))\n",
    "    cluster_list = [] # the corresponding clusters (lat, lon) to the x aggregate feature array\n",
    "    for i, g in enumerate(group):\n",
    "        lat, lon = g[0]\n",
    "        im_sub = df_consumption[(df_consumption['cluster_lat'] == lat) & (df_consumption['cluster_lon'] == lon)].reset_index(drop=True)\n",
    "        agg_feats = np.zeros((len(im_sub), 4096))\n",
    "        for j, d in im_sub.iterrows():\n",
    "            agg_feats[j,:] = feats[d.feat_index]\n",
    "        agg_feats = agg_feats.mean(axis=0) # averages the features across all images in the cluster\n",
    "\n",
    "        x[i,:] = agg_feats\n",
    "        cluster_list.append([lat, lon])\n",
    "    # save to the correct directory\n",
    "    save_dir = os.path.join(RESULTS_DIR, cd, 'cnn')\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    np.save(os.path.join(save_dir, 'cluster_feats.npy'), x)\n",
    "    pickle.dump(cluster_list, open(os.path.join(save_dir, 'cluster_order.pkl'), 'wb')) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m46"
  },
  "kernelspec": {
   "display_name": "predicting-poverty-replication",
   "language": "python",
   "name": "predicting-poverty-replication"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
